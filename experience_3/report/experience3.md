# ã€Šç¥ç»ç½‘ç»œä¸æ·±åº¦å­¦ä¹ ã€‹è¯¾ç¨‹å®éªŒä½œä¸šï¼ˆä¸‰ï¼‰

æ³¨æ„äº‹é¡¹ï¼š

â‘   æœ¬æ¬¡å®éªŒåŒ…å«ä¸¤é“é¢˜ï¼Œå…±è®¡30åˆ†ï¼›

â‘¡  æ‰€æœ‰å®éªŒç»“æœéœ€ä»¥å®éªŒæŠ¥å‘Šçš„å½¢å¼è¿›è¡Œæäº¤ï¼Œæ–‡ä»¶å‘½åæ ¼å¼ï¼šå®éªŒä¸‰_å§“å_å­¦å·.docxï¼Œæ–‡ä»¶ä¸­éœ€è¦å°†ä½œè€…è®¾ç½®ä¸ºæœ¬äººå§“åï¼›

â‘¢  å®éªŒæŠ¥å‘Šä¸­éœ€è¦æ’å…¥ä»£ç ç‰‡æ®µï¼Œå®Œæ•´ä»£ç æ— éœ€æ”¾åœ¨å®éªŒæŠ¥å‘Šä¸­ï¼Œä»¥å‹ç¼©åŒ…çš„å½¢å¼æ·»åŠ å³å¯ï¼Œå‹ç¼©åŒ…å‘½åæ ¼å¼ï¼šå®éªŒä¸‰_å§“å_å­¦å·.zipï¼›

â‘£  ä½œä¸šæäº¤æˆªæ­¢æ—¶é—´ï¼š2025å¹´12æœˆ31æ—¥æ™šä¸Š23ï¼š59

**åŸºäºMNISTæ•°æ®é›†çš„è‡ªç¼–ç å™¨å®ç°(15åˆ†)**

MNIST æ•°æ®é›†æ¥è‡ªç¾å›½å›½å®¶æ ‡å‡†ä¸æŠ€æœ¯ç ”ç©¶æ‰€, National Institute of Standards and Technology (NIST). è®­ç»ƒé›† (training set) ç”±æ¥è‡ª 250 ä¸ªä¸åŒäººæ‰‹å†™çš„æ•°å­—æ„æˆã€‚è¯·åŸºäºè¯¥æ•°æ®é›†ï¼Œå¹¶ç»“åˆæ‰€å­¦çŸ¥è¯†å®Œæˆä»¥ä¸‹å®éªŒå†…å®¹ï¼š

(1)   å®Œæˆæ•°æ®è¯»å†™å¹¶è¯•ç€**æ­å»ºæ·±åº¦è‡ªç¼–ç å™¨ç½‘ç»œ**ã€‚ä½¿ç”¨ print æ‰“å°ç½‘ç»œç»“æ„å¹¶å°†ç»“æœæˆªå›¾æ”¾å…¥å®éªŒæŠ¥å‘Šä¸­ã€‚(1åˆ†)

(2)   é€‰æ‹©äºŒå…ƒäº¤å‰ç†µå‡½æ•°ä½œä¸ºæŸå¤±å‡½æ•°ï¼Œåœ¨**é™åˆ¶ bottleneck å±‚ç»´åº¦ä¸º2çš„æƒ…å†µä¸‹è®­ç»ƒæ¨¡å‹**ã€‚ç»™å‡ºç›¸åº”ä»£ç æˆªå›¾ï¼Œå¹¶ç»™å‡ºæ•°å­—ä»0åˆ°9çš„10å¼ å›¾ç‰‡çš„åŸå§‹å›¾ç‰‡å’Œé‡å»ºå›¾ç‰‡ã€‚(3åˆ†)

(3)   è®¾ç½®**å™ªå£°å› å­ä¸º 0.4**ï¼Œåœ¨è¾“å…¥å›¾åƒä¸Šå åŠ å‡å€¼ä¸º0ä¸”æ–¹å·®ä¸º1çš„æ ‡å‡†é«˜æ–¯ç™½å™ªå£°ï¼Œ**è®­ç»ƒé™å™ªè‡ªç¼–ç å™¨** ï¼Œç»™å‡ºç›¸åº”çš„ä»£ç æˆªå›¾å’Œå…³é”®éƒ¨åˆ†ä»£ç è¯´æ˜ (4åˆ†)ï¼Œå¹¶è¿›è¡Œé™å™ªç»“æœå±•ç¤ºï¼Œç»™å‡ºæ•°å­—ä»0åˆ°9çš„10å¼ å›¾ç‰‡çš„åŸå§‹å›¾ç‰‡ã€åŠ å™ªå›¾ç‰‡å’Œé‡å»ºå›¾ç‰‡ã€‚(3åˆ†)ã€‚

ä»£ç ç¤ºä¾‹ï¼š

```
noise_factor = 0.4
x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape)
```

(4)   è¯•åœ¨é—®é¢˜(2)çš„åŸºç¡€ä¸Šï¼Œå¯¹ latent code è¿›è¡Œå‡åŒ€é‡‡æ ·ï¼Œå¹¶åˆ©ç”¨è§£ç å™¨å¯¹é‡‡æ ·ç»“æœè¿›è¡Œæ¢å¤ï¼Œå±•ç¤º latent code çš„åˆ†å¸ƒã€é‡‡æ ·èŒƒå›´å’Œé‡‡æ ·ç»“æœï¼Œè§‚å¯Ÿå¹¶æè¿°æ‰€å¾—åˆ°çš„ç»“æœã€‚(4åˆ†)

MNIST æ•°æ®é›†ä¸‹è½½ï¼šhttp://yann.lecun.com/exdb/mnist/

**å›¾åƒé£æ ¼è¿ç§»ï¼ˆ15åˆ†ï¼‰**

å›¾åƒé£æ ¼è¿ç§»ä»»åŠ¡æ˜¯å°†ä¸€å¹…å›¾åƒçš„é£æ ¼åº”ç”¨åˆ°å¦ä¸€å¹…å›¾åƒçš„å†…å®¹ä¸Šï¼Œä»è€Œç”Ÿæˆå…·æœ‰ç›®æ ‡é£æ ¼ç‰¹å¾çš„æ–°å›¾åƒã€‚åœ¨è¿‡å»çš„æ¢ç´¢ä¸­ï¼Œäººä»¬å‘ç°å›¾åƒé£æ ¼ä¸ latent code çš„ç»Ÿè®¡ç‰¹æ€§é«˜åº¦ç›¸å…³ï¼Œä¿®æ”¹ latent code çš„ç»Ÿè®¡ç‰¹æ€§å¯ä»¥å®ç°é£æ ¼è¿ç§»ã€‚ä¸€ç§ç®€å•ä½†é«˜æ•ˆçš„æ–¹æ³•æ˜¯åŸºäºInstance Normalization(IN)å®ç°ï¼Œåœ¨ä¸‹å›¾ä¸­ä½“ç°ä¸º AdaIN æ¨¡å—ã€‚AdaIN æ¨¡å—åŒæ—¶æ¥æ”¶ content çš„ latent code $x$ å’Œstyleçš„ latent code $y$ï¼Œç„¶ååŸºäºä¸‹è¿°å…¬å¼å¯¹é½å‡å€¼å’Œæ–¹å·®ï¼š
$$
AdaIN(x,y) = \sigma(y)(\frac{x - \mu(x)}{\sigma(x)})
$$
å¯¹ latent code çš„ç»Ÿè®¡ç‰¹æ€§è¿›è¡Œä¿®æ”¹åï¼Œå°†å…¶ç»“æœè¾“å…¥ç»™ decoderï¼Œå³å¯é‡å»ºå‡ºé£æ ¼è¿ç§»åçš„å›¾åƒã€‚åç»­é—®é¢˜æ˜¯å¦‚ä½•åœ¨æ²¡æœ‰é£æ ¼è¿ç§»ç»“æœçš„æ¡ä»¶ä¸‹è¿›è¡Œè‡ªç›‘ç£å­¦ä¹ ï¼Ÿ

ç­”æ¡ˆæ˜¯å†ç»è¿‡ä¸€éç¼–ç å™¨ï¼Œç”¨ latent code æ„å»ºè‡ªç›‘ç£å­¦ä¹ ã€‚è®° content å›¾åƒä¸º $c$ï¼Œstyle å›¾åƒä¸º $s$ï¼Œé¢„è®­ç»ƒçš„VGG Encoder ä¸º$f$ ï¼Œåˆ™é£æ ¼è¿ç§»åçš„ latent code ä¸º $t = AdaIN(f(c),f(s))$ã€‚ä½¿ç”¨ä¸€ä¸ªéšæœºåˆå§‹åŒ–çš„ Decoder $g$ å°† latent code æ˜ å°„ä¸ºå›¾åƒï¼Œç”Ÿæˆçš„é£æ ¼è¿ç§»å›¾åƒ $T(c,s) = g(t)$ã€‚

MS-COCO (Microsoft Common Objects in Context) æ˜¯ä¸€ä¸ªå¹¿æ³›åº”ç”¨äºè®¡ç®—æœºè§†è§‰çš„ç›®æ ‡æ£€æµ‹æ•°æ®é›†ï¼Œæœ¬æ¬¡å®éªŒé€‰å–å…¶ä¸­çš„ train2014 ä½œä¸º content å›¾åƒçš„è®­ç»ƒé›†ã€‚WikiArt æ•°æ®é›†æ˜¯ kaggle ä¸Šå¼€æºæ•°æ®é›†ï¼Œç”¨äº style å›¾åƒçš„è®­ç»ƒé›†ã€‚æ¯ä¸ªæ•°æ®é›†å¤§çº¦åŒ…å« 80,000 å¼ å›¾åƒã€‚è¯•åŸºäºä¸Šè¿°ä¸¤ä¸ªæ•°æ®é›†ï¼Œå®Œæˆä»¥ä¸‹å®éªŒå†…å®¹ï¼š

(1)   åŸºäºå¼€æºé¡¹ç›® https://github.com/naoto0804/pytorch-AdaIN.git è®­ç»ƒè‡ªå·±çš„é£æ ¼è¿ç§»æ¨¡å‹ï¼Œä½¿ç”¨tensorboardå¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹ï¼Œè¯·å°†è®­ç»ƒè¿‡ç¨‹çš„ç»“æœæ”¾å…¥å®éªŒæŠ¥å‘Šä¸­ã€‚ï¼ˆ(1)å’Œ(2)æ€»å…±åªéœ€è®­ç»ƒä¸€æ¬¡ï¼Œä½†æ³¨æ„ä¿å­˜è®­ç»ƒè¿‡ç¨‹ä¸­ä¸åŒé˜¶æ®µçš„æ¨¡å‹ï¼‰ï¼ˆ2åˆ†ï¼‰

(2)   è®­ç»ƒæ¨¡å‹çš„è¶…å‚æ•°å¯è‡ªè¡Œè°ƒæ•´ï¼Œä½†æ€»è¿­ä»£æ¬¡æ•°ä¸å¾—å°‘äº10000æ¬¡ã€‚ç»™å‡ºè¿­ä»£æ¬¡æ•°åˆ†åˆ«è¾¾åˆ°æ€»è¿­ä»£æ¬¡æ•°çš„10%ã€50%ã€ 80%å’Œ100%æ—¶çš„é£æ ¼è¿ç§»å›¾åƒç»“æœã€‚å…·ä½“è¦æ±‚æ˜¯ï¼Œcontent å›¾ç‰‡ä½¿ç”¨(1)ä¸­å¼€æºé¡¹ç›®çš„ input/content/cornell.jpgï¼Œstyle å›¾ç‰‡ä½¿ç”¨(1)ä¸­å¼€æºé¡¹ç›®çš„ input/style/woman_with_hat_matisse.jpgã€‚ï¼ˆ4åˆ†ï¼‰

(3)   è¯·å¤§å®¶ä»»é€‰åŒ—é‚®çš„2ä¸ªç‰¹è‰²æ™¯ç‚¹ï¼Œåˆ†åˆ«æ‹å–è‡ªå·±å’ŒåŒ—é‚®æ™¯ç‚¹çš„åˆç…§ï¼Œå¾—åˆ°ä¸¤å¼ ä¸åŒæ™¯ç‚¹çš„å›¾åƒã€‚é€‰å–ä¸€ç§é£æ ¼ï¼Œå¯¹ä¸¤å¼ å›¾åƒè¿›è¡Œé£æ ¼è¿ç§»ï¼Œå±•ç¤ºè¾“å…¥çš„ content å›¾åƒå’Œ style å›¾åƒä»¥åŠè¾“å‡ºçš„é£æ ¼è¿ç§»å›¾åƒã€‚ï¼ˆ6åˆ†ï¼‰

(4)   ä»»æ„é€‰å–ä¸Šè¿°(3)ä¸­ä¸€å¼ åˆç…§ï¼Œå¹¶ä½¿ç”¨å’Œ(3)ä¸­ä¸åŒçš„å›¾åƒé£æ ¼ï¼Œèµ‹äºˆAdaINçš„è¾“å‡ºæƒé‡ $\alpha$ï¼Œå¹¶èµ‹äºˆ content å›¾åƒé€šè¿‡VGG Encoderåçš„è¾“å‡ºæƒé‡ $1- \alpha$ã€‚å¯¹äºŒè€…åŠ æƒæ±‚å’Œåé€å…¥ decoderï¼Œè®¾ç½®ä¸åŒ $\alpha$ï¼Œå±•ç¤º style ä¸åŒå æ¯”æƒ…å†µä¸‹çš„é£æ ¼è¿ç§»ç»“æœã€‚å­¦å·å°¾å·ä¸ºå¶æ•°çš„åŒå­¦ $\alpha$ åˆ†åˆ«è®¾ç½®ä¸º0.3ï¼Œ0.6ï¼Œ0.9, å­¦å·å°¾å·ä¸ºå¥‡æ•°çš„åŒå­¦ $\alpha$åˆ†åˆ«è®¾ç½®ä¸º0.2ï¼Œ0.5ï¼Œ0.8ã€‚ï¼ˆ3åˆ†ï¼‰

---

# åŸºäºMNISTæ•°æ®é›†çš„è‡ªç¼–ç å™¨å®ç°

MNIST æ•°æ®é›†æ¥è‡ªç¾å›½å›½å®¶æ ‡å‡†ä¸æŠ€æœ¯ç ”ç©¶æ‰€, National Institute of Standards and Technology (NIST). è®­ç»ƒé›† (training set) ç”±æ¥è‡ª 250 ä¸ªä¸åŒäººæ‰‹å†™çš„æ•°å­—æ„æˆã€‚è¯·åŸºäºè¯¥æ•°æ®é›†ï¼Œå¹¶ç»“åˆæ‰€å­¦çŸ¥è¯†å®Œæˆä»¥ä¸‹å®éªŒå†…å®¹ï¼š

(1)   å®Œæˆæ•°æ®è¯»å†™å¹¶è¯•ç€**æ­å»ºæ·±åº¦è‡ªç¼–ç å™¨ç½‘ç»œ**ã€‚ä½¿ç”¨ print æ‰“å°ç½‘ç»œç»“æ„å¹¶å°†ç»“æœæˆªå›¾æ”¾å…¥å®éªŒæŠ¥å‘Šä¸­ã€‚(1åˆ†)

(2)   é€‰æ‹©äºŒå…ƒäº¤å‰ç†µå‡½æ•°ä½œä¸ºæŸå¤±å‡½æ•°ï¼Œåœ¨**é™åˆ¶ bottleneck å±‚ç»´åº¦ä¸º2çš„æƒ…å†µä¸‹è®­ç»ƒæ¨¡å‹**ã€‚ç»™å‡ºç›¸åº”ä»£ç æˆªå›¾ï¼Œå¹¶ç»™å‡ºæ•°å­—ä»0åˆ°9çš„10å¼ å›¾ç‰‡çš„åŸå§‹å›¾ç‰‡å’Œé‡å»ºå›¾ç‰‡ã€‚(3åˆ†)

(3)   è®¾ç½®**å™ªå£°å› å­ä¸º 0.4**ï¼Œåœ¨è¾“å…¥å›¾åƒä¸Šå åŠ å‡å€¼ä¸º0ä¸”æ–¹å·®ä¸º1çš„æ ‡å‡†é«˜æ–¯ç™½å™ªå£°ï¼Œ**è®­ç»ƒé™å™ªè‡ªç¼–ç å™¨** ï¼Œç»™å‡ºç›¸åº”çš„ä»£ç æˆªå›¾å’Œå…³é”®éƒ¨åˆ†ä»£ç è¯´æ˜ (4åˆ†)ï¼Œå¹¶è¿›è¡Œé™å™ªç»“æœå±•ç¤ºï¼Œç»™å‡ºæ•°å­—ä»0åˆ°9çš„10å¼ å›¾ç‰‡çš„åŸå§‹å›¾ç‰‡ã€åŠ å™ªå›¾ç‰‡å’Œé‡å»ºå›¾ç‰‡ã€‚(3åˆ†)ã€‚

(4)   è¯•åœ¨é—®é¢˜(2)çš„åŸºç¡€ä¸Šï¼Œå¯¹ latent code è¿›è¡Œå‡åŒ€é‡‡æ ·ï¼Œå¹¶åˆ©ç”¨è§£ç å™¨å¯¹é‡‡æ ·ç»“æœè¿›è¡Œæ¢å¤ï¼Œå±•ç¤º latent code çš„åˆ†å¸ƒã€é‡‡æ ·èŒƒå›´å’Œé‡‡æ ·ç»“æœï¼Œè§‚å¯Ÿå¹¶æè¿°æ‰€å¾—åˆ°çš„ç»“æœã€‚(4åˆ†)

## ä»£ç ç»“æ„

```python
ğŸ“¦self_encoding
 â”£ ğŸ“‚dataset
 â”£ ğŸ“‚results
 â”ƒ â”£ ğŸ“œautoencoder.pth # æ·±åº¦è‡ªç¼–ç å™¨æ¨¡å‹è¾“å‡º
 â”ƒ â”£ ğŸ“œdenoise_autoencoder.pth # é™å™ªè‡ªç¼–ç å™¨æ¨¡å‹è¾“å‡º
 â”ƒ â”£ ğŸ“œdenoise_loss_curve.png 
 â”ƒ â”£ ğŸ“œdenoising_result.png # é™å™ªé‡æ„ç»“æœ
 â”ƒ â”£ ğŸ“œlatent_distribution.png # ä»»åŠ¡å››äºŒç»´èšç±»å›¾
 â”ƒ â”£ ğŸ“œlatent_sampling.png # ä»»åŠ¡å››é¢„æµ‹å›¾
 â”ƒ â”£ ğŸ“œloss_curve.png # SAE è®­ç»ƒæŸå¤±æ›²çº¿
 â”ƒ â”— ğŸ“œreconstruction.png # SAEé‡å»ºå›¾ç‰‡
 â”£ ğŸ“œdataloader.py
 â”£ ğŸ“œdata_download.py
 â”£ ğŸ“œdenoise_train.py 
 â”£ ğŸ“œmodel.py # SAE æ¨¡å‹ç»“æ„
 â”£ ğŸ“œtrain.py
 â”— ğŸ“œvisualize_latent.py
```



## 1. å®Œæˆæ•°æ®è¯»å†™å¹¶è¯•ç€æ­å»ºæ·±åº¦è‡ªç¼–ç å™¨ç½‘ç»œ

### 1.1. ä»kaggleä¸Šä¸‹è½½æ•°æ®

```python
import kagglehub

# Download latest version
path = kagglehub.dataset_download("hojjatk/mnist-dataset")

print("Path to dataset files:", path)
```

### 1.2. æ­å»ºè‡ªç¼–ç å™¨ç½‘ç»œ

æ ¹æ®æ–‡ç« ï¼šhttps://zhuanlan.zhihu.com/p/133207206ä¸­å¯¹è‡ªç¼–ç å™¨çš„ä»‹ç»ï¼šå¯çŸ¥è‡ªç¼–ç å™¨çš„æœ¬è´¨æ˜¯"æ¨¡ä»¿"ï¼Œé€šè¿‡é‡å»ºåŸå›¾ç‰‡ï¼Œå®ç°éçº¿æ€§å˜æ¢çš„é™ç»´ï¼Œè€Œä¸æ˜¯åƒ PCA ä¸€æ ·çš„çº¿æ€§é™ç»´ï¼Œè¿›è€Œæ‹¥æœ‰æ›´å¥½åœ°æ‹Ÿåˆèƒ½åŠ›ã€‚

**ä¸ºè·å¾—æ›´å¥½çš„æ‹Ÿåˆæ•ˆæœ**ï¼Œæ­¤å¤„é‡‡ç”¨æ ˆå¼è‡ªç¼–ç å™¨ SAEï¼Œç½‘ç»œç»“æ„å¦‚ä¸‹ï¼š

```bash
æ¨¡å‹ç»“æ„:
AutoEncoder(
  (encoder): Sequential(
    (0): Flatten(start_dim=1, end_dim=-1)
    (1): Linear(in_features=784, out_features=512, bias=True)
    (2): LeakyReLU(negative_slope=0.02)
    (3): Linear(in_features=512, out_features=128, bias=True)
    (4): LeakyReLU(negative_slope=0.02)
    (5): Linear(in_features=128, out_features=64, bias=True)
    (6): LeakyReLU(negative_slope=0.02)
    (7): Linear(in_features=64, out_features=10, bias=True)
    (8): LeakyReLU(negative_slope=0.02)
    (9): Linear(in_features=10, out_features=2, bias=True)
  )
  (decoder): Sequential(
    (0): Linear(in_features=2, out_features=10, bias=True)
    (1): LeakyReLU(negative_slope=0.02)
    (2): Linear(in_features=10, out_features=64, bias=True)
    (3): LeakyReLU(negative_slope=0.02)
    (4): Linear(in_features=64, out_features=128, bias=True)
    (5): LeakyReLU(negative_slope=0.02)
    (6): Linear(in_features=128, out_features=512, bias=True)
    (7): LeakyReLU(negative_slope=0.02)
    (8): Linear(in_features=512, out_features=784, bias=True)
    (9): Sigmoid()
  )
)
```

```mermaid
graph TD
    %% å®šä¹‰æ ·å¼
    classDef input fill:#e1f5fe,stroke:#01579b,stroke-width:2px,rx:5,ry:5;
    classDef layer fill:#fff9c4,stroke:#fbc02d,stroke-width:1px;
    classDef act fill:#f3e5f5,stroke:#7b1fa2,stroke-width:1px,stroke-dasharray: 5 5;
    classDef bottleneck fill:#ffcc80,stroke:#e65100,stroke-width:4px,rx:10,ry:10;
    classDef output fill:#ccff90,stroke:#33691e,stroke-width:2px,rx:5,ry:5;
    classDef group style fill:#f5f5f5,stroke:#999,stroke-width:2px,stroke-dasharray: 5 5;

    %% è¾“å…¥å±‚
    Input([Input Image<br/>1x28x28]):::input
    
    %% ç¼–ç å™¨éƒ¨åˆ†
    subgraph Encoder_Block [Encoder]
        direction TB
        Flatten[Flatten<br/>28x28 -> 784]:::layer
        
        E_L1[Linear<br/>784 -> 512]:::layer
        E_A1(LeakyReLU):::act
        
        E_L2[Linear<br/>512 -> 128]:::layer
        E_A2(LeakyReLU):::act
        
        E_L3[Linear<br/>128 -> 64]:::layer
        E_A3(LeakyReLU):::act
        
        E_L4[Linear<br/>64 -> 10]:::layer
        E_A4(LeakyReLU):::act
        
        E_L5[Linear<br/>10 -> 2]:::layer
    end

    %% ç“¶é¢ˆå±‚
    Bottleneck((Latent Code<br/>dim=2)):::bottleneck

    %% è§£ç å™¨éƒ¨åˆ†
    subgraph Decoder_Block [Decoder]
        direction TB
        D_L1[Linear<br/>2 -> 10]:::layer
        D_A1(LeakyReLU):::act
        
        D_L2[Linear<br/>10 -> 64]:::layer
        D_A2(LeakyReLU):::act
        
        D_L3[Linear<br/>64 -> 128]:::layer
        D_A3(LeakyReLU):::act
        
        D_L4[Linear<br/>128 -> 512]:::layer
        D_A4(LeakyReLU):::act
        
        D_L5[Linear<br/>512 -> 784]:::layer
        D_Sig(Sigmoid):::act
    end

    %% è¾“å‡ºå±‚
    Reshape[Reshape<br/>784 -> 1x28x28]:::layer
    Output([Reconstructed Image<br/>1x28x28]):::output

    %% è¿æ¥å…³ç³»
    Input --> Flatten
    Flatten --> E_L1 --> E_A1
    E_A1 --> E_L2 --> E_A2
    E_A2 --> E_L3 --> E_A3
    E_A3 --> E_L4 --> E_A4
    E_A4 --> E_L5
    
    E_L5 --> Bottleneck
    
    Bottleneck --> D_L1 --> D_A1
    D_A1 --> D_L2 --> D_A2
    D_A2 --> D_L3 --> D_A3
    D_A3 --> D_L4 --> D_A4
    D_A4 --> D_L5 --> D_Sig
    
    D_Sig --> Reshape --> Output
```



### 1.3. ç¼–å†™æ•°æ®åŠ è½½å™¨è„šæœ¬

```python
class MNISTDataset(Dataset):
    """è‡ªå®šä¹‰MNISTæ•°æ®é›†åŠ è½½å™¨ï¼Œä»idxæ–‡ä»¶è¯»å–"""
    def __init__(self, data_dir, train=True, transform=None):
        """
        Args:
            data_dir: æ•°æ®é›†ç›®å½•è·¯å¾„
            train: TrueåŠ è½½è®­ç»ƒé›†ï¼ŒFalseåŠ è½½æµ‹è¯•é›†
            transform: å¯é€‰çš„æ•°æ®å˜æ¢
        """
def get_dataloader(data_dir, batch_size=256, train=True, shuffle=True, num_workers=4):
    """
    è·å–MNISTæ•°æ®åŠ è½½å™¨
    Args:
        data_dir: æ•°æ®é›†ç›®å½•
        batch_size: æ‰¹æ¬¡å¤§å°
        train: æ˜¯å¦ä¸ºè®­ç»ƒé›†
        shuffle: æ˜¯å¦æ‰“ä¹±æ•°æ®
        num_workers: æ•°æ®åŠ è½½çº¿ç¨‹æ•°

    Returns:
        DataLoaderå¯¹è±¡
    """
def get_samples(data_dir, train=False):
    """
    è·å–æ¯ä¸ªæ•°å­—(0-9)çš„ä¸€ä¸ªæ ·æœ¬
    Args:
        data_dir: æ•°æ®é›†ç›®å½•
        train: æ˜¯å¦ä»è®­ç»ƒé›†è·å–

    Returns:
        images: shape (10, 1, 28, 28) çš„tensor
        labels: 0-9çš„æ ‡ç­¾åˆ—è¡¨
    """
```

## 2. æ¨¡å‹è®­ç»ƒ

å¯¹ SAE è¿›è¡Œè®­ç»ƒï¼Œç”±äºæ˜¯æ— ç›‘ç£å­¦ä¹ ï¼Œå› æ­¤ä¸éœ€è¦ä½¿ç”¨å›¾ç‰‡æ ‡ç­¾è¿›è¡Œè®­ç»ƒã€‚

**æ·±åº¦è‡ªç¼–ç å™¨è®­ç»ƒ**

```python
 # mainå‡½æ•°ä¸­
    batch_size = 256
    learning_rate = 1e-3
    epochs = 100
    data_dir = './dataset'
    save_path = './results'
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    train_loader = get_dataloader(data_dir, batch_size=batch_size, train=True)
    print(f"è®­ç»ƒé›†å¤§å°: {len(train_loader.dataset)}")

    model = AutoEncoder().to(device)
    print("\næ¨¡å‹ç»“æ„:")
    print(model)

    loss_fn = nn.BCELoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)

    print("\nå¼€å§‹è®­ç»ƒ...")
    loss_history = train(model, train_loader, loss_fn, optimizer, scheduler,device, epochs)

    # ä¿å­˜æ¨¡å‹
    os.makedirs(save_path, exist_ok=True)
    model_path = os.path.join(save_path, 'autoencoder.pth')
    torch.save(model.state_dict(), model_path)
    print(f"\næ¨¡å‹å·²ä¿å­˜åˆ° {model_path}")

    # å¯è§†åŒ–ç»“æœ
    plot_loss(loss_history, save_path)
    visualize_reconstruction(model, data_dir, device, save_path)
```

**è®­ç»ƒè¿‡ç¨‹**ï¼š

```bash
å¼€å§‹è®­ç»ƒ...
Epoch [10/100], Loss: 0.175239, Learning Rate: 0.001000
Epoch [20/100], Loss: 0.170615, Learning Rate: 0.001000
Epoch [30/100], Loss: 0.166886, Learning Rate: 0.001000
Epoch [40/100], Loss: 0.165478, Learning Rate: 0.001000
Epoch [50/100], Loss: 0.161814, Learning Rate: 0.000100
Epoch [60/100], Loss: 0.160716, Learning Rate: 0.000100
Epoch [70/100], Loss: 0.160104, Learning Rate: 0.000100
Epoch [80/100], Loss: 0.159168, Learning Rate: 0.000100
Epoch [90/100], Loss: 0.158734, Learning Rate: 0.000100
Epoch [100/100], Loss: 0.158320, Learning Rate: 0.000100

æ¨¡å‹å·²ä¿å­˜åˆ° ./results/autoencoder.pth
é‡å»ºç»“æœå·²ä¿å­˜åˆ° ./results/reconstruction.png
```

**æŸå¤±æ›²çº¿**

![1](./loss_curve.png)

**è®­ç»ƒç»“æœ**

![2](./reconstruction.png)

## 3. é™å™ªè‡ªç¼–ç å™¨è®­ç»ƒ

```python
def main():
    # è¶…å‚æ•°
    batch_size = 256
    learning_rate = 1e-3
    epochs = 120
    noise_factor = 0.4
    data_dir = './dataset'
    save_path = './results'

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    train_loader = get_dataloader(data_dir, batch_size=batch_size, train=True)
    print(f"è®­ç»ƒé›†å¤§å°: {len(train_loader.dataset)}")

    model = AutoEncoder().to(device)
    print("\næ¨¡å‹ç»“æ„:")
    print(model)

    loss_fn = nn.BCELoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)

    # è®­ç»ƒ
    print(f"\nå¼€å§‹è®­ç»ƒé™å™ªè‡ªç¼–ç å™¨ (å™ªå£°å› å­: {noise_factor})...")
    loss_history = train_denoising(
        model=model,
        train_loader=train_loader,
        loss_fn=loss_fn,
        optimizer=optimizer,
        scheduler=scheduler,
        device=device,
        epochs=epochs,
        noise_factor=noise_factor)

    # ä¿å­˜æ¨¡å‹
    os.makedirs(save_path, exist_ok=True)
    model_path = os.path.join(save_path, 'denoise_autoencoder.pth')
    torch.save(model.state_dict(), model_path)
    print(f"\næ¨¡å‹å·²ä¿å­˜åˆ° {model_path}")

    # å¯è§†åŒ–ç»“æœ
    plot_loss(loss_history, save_path)
    visualize_denoising(model, data_dir, device, noise_factor, save_path)
```

**è®­ç»ƒè¿‡ç¨‹**

```bash
å¼€å§‹è®­ç»ƒé™å™ªè‡ªç¼–ç å™¨ (å™ªå£°å› å­: 0.4)...
Epoch [10/120], Loss: 0.182431, Learning Rate: 0.001000
Epoch [20/120], Loss: 0.176919, Learning Rate: 0.001000
Epoch [30/120], Loss: 0.176220, Learning Rate: 0.001000
Epoch [40/120], Loss: 0.172335, Learning Rate: 0.001000
Epoch [50/120], Loss: 0.173927, Learning Rate: 0.001000
Epoch [60/120], Loss: 0.170303, Learning Rate: 0.001000
Epoch [70/120], Loss: 0.166664, Learning Rate: 0.000100
Epoch [80/120], Loss: 0.166088, Learning Rate: 0.000100
Epoch [90/120], Loss: 0.165643, Learning Rate: 0.000100
Epoch [100/120], Loss: 0.165194, Learning Rate: 0.000100
Epoch [110/120], Loss: 0.165154, Learning Rate: 0.000100
Epoch [120/120], Loss: 0.164589, Learning Rate: 0.000100

æ¨¡å‹å·²ä¿å­˜åˆ° ./results/denoise_autoencoder.pth
æŸå¤±æ›²çº¿å·²ä¿å­˜åˆ° ./results/denoise_loss_curve.png
é™å™ªç»“æœå·²ä¿å­˜åˆ° ./results/denoising_result.png
```

**æŸå¤±æ›²çº¿**

![3](./denoise_loss_curve.png)

**è®­ç»ƒç»“æœ**

![4](./denoising_result.png)

## 4. Latent Code é‡‡æ ·ä¸å¯è§†åŒ–

å¯¹ latent code è¿›è¡Œå‡åŒ€é‡‡æ ·ï¼Œå¹¶åˆ©ç”¨è§£ç å™¨å¯¹é‡‡æ ·ç»“æœè¿›è¡Œæ¢å¤ï¼š

1.  ä¸¢æ‰ Encodeï¼Œåªä½¿ç”¨è®­ç»ƒå¥½çš„ Decoder
2.  æ„é€  Latent Vectorï¼Œåœ¨äºŒç»´çš„ latent ç©ºé—´åˆ†å¸ƒä¸Šï¼Œä½¿ç”¨ä¸¤ä¸ªç»´åº¦çš„é‡ç¨‹ä½œä¸ºå‡åŒ€é‡‡æ ·çš„èŒƒå›´ï¼Œé‡‡æ ·æ•°ä¸º20
3.  å¯¹é‡‡æ ·å€¼è¿›è¡Œè§£ç é‡å»º

```python
def main():
    data_dir = './dataset'
    save_path = './results'
    model_path = os.path.join(save_path, 'autoencoder.pth')
    n_samples = 20

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")

    model = AutoEncoder().to(device)
    if os.path.exists(model_path):
        model.load_state_dict(torch.load(model_path, map_location=device))
        print(f"å·²åŠ è½½æ¨¡å‹: {model_path}")
    else:
        print(f"Error: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {model_path}")
        print("è¯·å…ˆè¿è¡Œ train.py è®­ç»ƒæ¨¡å‹")
        return

    test_loader = get_dataloader(data_dir, batch_size=256, train=False, shuffle=False)
    print(f"æµ‹è¯•é›†å¤§å°: {len(test_loader.dataset)}")

    print("\n1. å¯è§†åŒ–Latent Spaceåˆ†å¸ƒ...")
    x_min, x_max, y_min, y_max = visualize_latent_distribution(model, test_loader, device, save_path)

    print(f"\n2. åœ¨Latent Spaceä¸­å‡åŒ€é‡‡æ · ({n_samples}x{n_samples})...")
    margin = 0.5
    sample_and_decode(
        model, device,
        x_range=(x_min - margin, x_max + margin),
        y_range=(y_min - margin, y_max + margin),
        n_samples=n_samples,
        save_path=save_path
    )
```

### 4.1. æ‰€æœ‰æµ‹è¯•æ•°æ®åœ¨ latent space ä¸­çš„åˆ†å¸ƒ

![5](./latent_distribution.png)



**ç»“æœåˆ†æ**ï¼š

1. æ•°å­—0ã€1ã€2ã€5çš„ç°‡ç›¸å¯¹ç‹¬ç«‹ï¼Œä¸å…¶ä»–æ•°å­—è¾ƒä¸ºåˆ†æ•£ã€‚æ•°å­—1å’Œ2çš„ç°‡ååˆ†ç´§å¯†ã€‚
2. å…¶ä»–æ•°å­—åŸºæœ¬æ··å åœ¨ä¸­å¿ƒåŒºåŸŸï¼Œé™¤äº†æ•°å­—6å’Œ3ç¨å¾®åˆ†ç¦»ä¸€äº›ã€‚
3. åæ ‡è½´èŒƒå›´ä¸º [-30, 50], [-30, 80]ï¼Œå±•ç¤ºäº†è¿™æ˜¯ä¸ªæ™®é€š AEï¼Œé VAE å°†åˆ†å¸ƒçº¦æŸä¸ºæ ‡å‡†æ­£æ€åˆ†å¸ƒ

### 4.2.é‡‡æ ·é‡å»ºç»“æœ

![6](./latent_sampling.png)



**ç»“æœåˆ†æ**ï¼š

é‡‡æ ·é‡å»ºå›¾éªŒè¯äº†åæ ‡ä¸å›¾åƒå†…å®¹çš„å¯¹åº”å…³ç³»ã€‚å·¦ä¾§åæ ‡ç¨³å®šç”Ÿæˆ0ï¼Œè¯æ˜äº† Decoder å­¦ä¹ åˆ°äº†åæ ‡åˆ°å›¾åƒçš„æ˜ å°„è§„åˆ™ã€‚ä½†æ˜¯é‡‡æ ·å›¾ä¸­å­˜åœ¨å¤§é‡é‡å¤å›¾åƒï¼Œè¯´æ˜æ½œåœ¨ç©ºé—´å¹¶éè¿ç»­å¯†å¸ƒçš„ï¼Œå³å­˜åœ¨ç©ºæ´ã€‚æ¨¡å‹åœ¨æœªè§è¿‡çš„åæ ‡ç‚¹ä¸Šçš„æ³›åŒ–èƒ½åŠ›ä¸»è¦è¡¨ç°ä¸ºå¯¹æœ€è¿‘é‚»æ ·æœ¬çš„é€¼è¿‘ã€‚

---

# å›¾åƒé£æ ¼è¿ç§»

(1)   åŸºäºå¼€æºé¡¹ç›® https://github.com/naoto0804/pytorch-AdaIN.git è®­ç»ƒè‡ªå·±çš„é£æ ¼è¿ç§»æ¨¡å‹ï¼Œä½¿ç”¨tensorboardå¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹ï¼Œè¯·å°†è®­ç»ƒè¿‡ç¨‹çš„ç»“æœæ”¾å…¥å®éªŒæŠ¥å‘Šä¸­ã€‚ï¼ˆ(1)å’Œ(2)æ€»å…±åªéœ€è®­ç»ƒä¸€æ¬¡ï¼Œä½†æ³¨æ„ä¿å­˜è®­ç»ƒè¿‡ç¨‹ä¸­ä¸åŒé˜¶æ®µçš„æ¨¡å‹ï¼‰ï¼ˆ2åˆ†ï¼‰

(2)   è®­ç»ƒæ¨¡å‹çš„è¶…å‚æ•°å¯è‡ªè¡Œè°ƒæ•´ï¼Œä½†æ€»è¿­ä»£æ¬¡æ•°ä¸å¾—å°‘äº10000æ¬¡ã€‚ç»™å‡ºè¿­ä»£æ¬¡æ•°åˆ†åˆ«è¾¾åˆ°æ€»è¿­ä»£æ¬¡æ•°çš„10%ã€50%ã€ 80%å’Œ100%æ—¶çš„é£æ ¼è¿ç§»å›¾åƒç»“æœã€‚å…·ä½“è¦æ±‚æ˜¯ï¼Œcontent å›¾ç‰‡ä½¿ç”¨(1)ä¸­å¼€æºé¡¹ç›®çš„ input/content/cornell.jpgï¼Œstyle å›¾ç‰‡ä½¿ç”¨(1)ä¸­å¼€æºé¡¹ç›®çš„ input/style/woman_with_hat_matisse.jpgã€‚ï¼ˆ4åˆ†ï¼‰

(3)   è¯·å¤§å®¶ä»»é€‰åŒ—é‚®çš„2ä¸ªç‰¹è‰²æ™¯ç‚¹ï¼Œåˆ†åˆ«æ‹å–è‡ªå·±å’ŒåŒ—é‚®æ™¯ç‚¹çš„åˆç…§ï¼Œå¾—åˆ°ä¸¤å¼ ä¸åŒæ™¯ç‚¹çš„å›¾åƒã€‚é€‰å–ä¸€ç§é£æ ¼ï¼Œå¯¹ä¸¤å¼ å›¾åƒè¿›è¡Œé£æ ¼è¿ç§»ï¼Œå±•ç¤ºè¾“å…¥çš„ content å›¾åƒå’Œ style å›¾åƒä»¥åŠè¾“å‡ºçš„é£æ ¼è¿ç§»å›¾åƒã€‚ï¼ˆ6åˆ†ï¼‰

(4)   ä»»æ„é€‰å–ä¸Šè¿°(3)ä¸­ä¸€å¼ åˆç…§ï¼Œå¹¶ä½¿ç”¨å’Œ(3)ä¸­ä¸åŒçš„å›¾åƒé£æ ¼ï¼Œèµ‹äºˆAdaINçš„è¾“å‡ºæƒé‡ $\alpha$ï¼Œå¹¶èµ‹äºˆ content å›¾åƒé€šè¿‡VGG Encoderåçš„è¾“å‡ºæƒé‡ $1- \alpha$ã€‚å¯¹äºŒè€…åŠ æƒæ±‚å’Œåé€å…¥ decoderï¼Œè®¾ç½®ä¸åŒ $\alpha$ï¼Œå±•ç¤º style ä¸åŒå æ¯”æƒ…å†µä¸‹çš„é£æ ¼è¿ç§»ç»“æœã€‚å­¦å·å°¾å·ä¸ºå¶æ•°çš„åŒå­¦ $\alpha$ åˆ†åˆ«è®¾ç½®ä¸º0.3ï¼Œ0.6ï¼Œ0.9, å­¦å·å°¾å·ä¸ºå¥‡æ•°çš„åŒå­¦ $\alpha$åˆ†åˆ«è®¾ç½®ä¸º0.2ï¼Œ0.5ï¼Œ0.8ã€‚ï¼ˆ3åˆ†)

---

## ä»£ç ç»“æ„

```python
ğŸ“¦pytorch-AdaIN
 â”£ ğŸ“‚dataset # æ•°æ®é›†
 â”ƒ â”£ ğŸ“‚COCO
 â”ƒ â”— ğŸ“‚Wiki-art
 â”£ ğŸ“‚experiments # decodeæ¨¡å‹æŒä¹…åŒ–ï¼šepoch 1000, 5000, 8000, 10000
 â”£ ğŸ“‚input
 â”ƒ â”£ ğŸ“‚content
 â”ƒ â”ƒ â”£ ğŸ“œbupt1.jpg # ä»»åŠ¡ä¸‰å›¾ç‰‡ä¸€
 â”ƒ â”ƒ â”£ ğŸ“œbupt2.jpg # äººåœŸä¸‰å›¾ç‰‡äºŒ
 â”£ ğŸ“‚models
 â”£ ğŸ“‚output # ä»»åŠ¡ä¸‰ã€å››é£æ ¼è¿ç§»çš„å›¾ç‰‡è¾“å‡º
 â”£ ğŸ“‚output_iterations # ä»»åŠ¡äºŒçš„ä¸åŒè®­ç»ƒè½®æ¬¡çš„decodeé£æ ¼è¿ç§»å›¾ç‰‡è¾“å‡º
 â”£ ğŸ“‚runs # Tensorboard æŸå¤±å€¼æ›²çº¿ç»˜åˆ¶
 â”£ ğŸ“œfunction.py
 â”£ ğŸ“œnet.py
 â”£ ğŸ“œsampler.py
 â”£ ğŸ“œtest.py
 â”£ ğŸ“œtest_iterations.py # æµ‹è¯•ä¸åŒè¿­ä»£æ¬¡æ•°çš„æ¨¡å‹æ•ˆæœ
 â”£ ğŸ“œtest_video.py
 â”£ ğŸ“œtorch_to_pytorch.py
 â”— ğŸ“œtrain.py
```



## 1. å¤ç°å’Œæ¨¡å‹è®­ç»ƒ

> **AdaIN** å®ç°ä¸€ä¸ªæ¨¡å‹å¯è®­ç»ƒå¤šç§é£æ ¼çš„æ–¹æ³•ï¼š
>
> ä»¥å‰çš„æ–¹æ³•è®­ç»ƒä¸€ä¸ªç½‘ç»œåªèƒ½è¿ç§»ä¸€ç§é£æ ¼ï¼ˆä¾‹å¦‚æ¢µé«˜ï¼‰ï¼Œæ¢é£æ ¼éœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹ã€‚è€Œ AdaIN æå‡ºä¸€ç§åŠæ³•ï¼šå°†é£æ ¼å®šä¹‰ä¸ºç‰¹å¾å±‚çš„å‡å€¼ï¼ˆMeanï¼‰å’Œæ–¹å·®ï¼ˆVarianceï¼‰ï¼š
>
> 1. æŠŠå†…å®¹å›¾ï¼ˆContentï¼‰çš„ç‰¹å¾å‡å€¼æ–¹å·®æŠ¹å»
> 2. æ¢ä¸Šé£æ ¼å›¾ï¼ˆStyleï¼‰çš„ç‰¹å¾å‡å€¼æ–¹å·®
> 3. è¿™æ · Decoder è¿˜åŸå‡ºæ¥çš„å°±æ˜¯å†…å®¹å›¾çš„éª¨æ¶ + é£æ ¼å›¾çš„çš®
>
> å…¬å¼ï¼š
> $$
> AdaIN(x,y) = \sigma(y)(\frac{x - \mu(x)}{\sigma(x)}) + \mu(y)
> $$

åœ¨ `train.py` ä¸­æ·»åŠ å‚æ•°ï¼š

```python
parser.add_argument('--log_dir', default='./runs',
                    help='Directory to save the TensorBoard log')
```

åœ¨è®­ç»ƒå¾ªç¯ä¸­æ·»åŠ ï¼š

```python
    writer.add_scalar('loss_content', loss_c.item(), i + 1)
    writer.add_scalar('loss_style', loss_s.item(), i + 1)
    writer.add_scalar('loss_total', loss.item(), i + 1)
```

å°†æ¯ä¸€è½®æ¬¡çš„å†…å®¹å›¾çš„è®­ç»ƒæŸå¤± `loss_c`ã€é£æ ¼å›¾çš„è®­ç»ƒæŸå¤± `loss_s` ä»¥åŠæ€»çš„è®­ç»ƒæŸå¤± `loss = c + s` å†™å…¥æ—¥å¿—ã€‚

å¾—åˆ°ä»¥ä¸‹ loss æ›²çº¿å›¾ï¼š

**æ€»çš„è®­ç»ƒæŸå¤±**

![1](./loss_total.jpg)

**å†…å®¹å›¾è®­ç»ƒæŸå¤±**

![2](./loss_content.jpg)

**é£æ ¼å›¾è®­ç»ƒæŸå¤±**

![2](./loss_style.jpg)

---

## 2. è¿‡ç¨‹å¯è§†åŒ–

**æ¨¡å‹è®­ç»ƒæŒ‡ä»¤**ï¼š

```bash
python train.py --content_dir dataset/coco --style_dir dataset/wikiart --max_iter 10000 --batch_size 8 __n_threads 8
```

æ¨¡å‹çš„æŒä¹…åŒ–ï¼šåœ¨ `./experiments` ä¸‹

- `decoder_iter_1000.pth.tar`
- `decoder_iter_5000.pth.tar`
- `decoder_iter_8000.pth.tar`
- `decoder_iter_10000.pth.tar`

æ‰§è¡Œè„šæœ¬ï¼š

```bash
python test_iterations.py --max_iter 10000
```

>  `test_iterations.py` ä¸“é—¨ç”¨äºç”Ÿæˆä¸åŒè¿­ä»£æ¬¡æ•°çš„é£æ ¼è¿ç§»ç»“æœï¼Œç»“æœè¾“å‡ºåˆ° `./output_iterations/` ç›®å½•

**ç»“æœå±•ç¤º**

**åŸå†…å®¹å›¾**ï¼š

![5](./content.jpg)

**å‚è€ƒé£æ ¼å›¾**

![6](./style.jpg)

**æ•ˆæœå›¾**ï¼š

**è¿­ä»£æ¬¡æ•°10%**

![7](./stylized_10%_iter1000.jpg)

**è¿­ä»£æ¬¡æ•°50%**

![7](./stylized_50%_iter5000.jpg)

**è¿­ä»£æ¬¡æ•°80%**

![8](./stylized_80%_iter8000.jpg)

**è¿­ä»£æ¬¡æ•°100%**

![9](./stylized_100%_iter10000.jpg)

---

## 3.åŒ—é‚®ç‰¹è‰²æ™¯ç‚¹æ‰“å¡ 

è¾“å…¥æŒ‡ä»¤ï¼š

```bash
python test.py --content bupt1.jpg --style input/style/picasso_seated_nude_hr.jpg --decoder experiments/decoder_iter_10000.pth.tar
python test.py --content input/content/bupt2.jpg --style input/style/picasso_seated_nude_hr.jpg --decoder experiments/decoder_iter_10000.pth.tar
```

### è¾“å…¥çš„ content å›¾åƒ

**bupt1**

![10](./bupt1.jpg)

**bupt2**

![11](./bupt2.jpg)

---

### è¾“å‡ºçš„é£æ ¼å›¾

**bupt1ç´ æ**

![bupt1_stylized_sketch_alpha_1.jpg](./bupt1_stylized_sketch_alpha_1.jpg)

**bupt2æ¯•åŠ ç´¢**

![bupt2_stylized_picasso_seated_nude_hr_alpha_1.000000.jpg](./bupt2_stylized_picasso_seated_nude_hr_alpha_1.000000.jpg)

> ä¸‘æ­»æˆ‘äº†

---

## 4. Alpha ($\alpha$) æƒé‡æ§åˆ¶

**å­¦å·å°¾æ•°684ï¼Œæ•… $\alpha$ å–å€¼ä¸º $0.3,0.6,0.9$**ã€‚

è§‚å¯Ÿ `test.py` ä¸­çš„ `style_transfer`ï¼Œå…¶å·²ç»å®ç°é¢˜ç›®çš„è¦æ±‚ï¼Œåªéœ€è¦è¿ç»­è¿è¡Œä¸‰æ¬¡ï¼ŒæŒ‡å®šä¸åŒçš„ $\alpha$ å³å¯ã€‚

```python
def style_transfer(vgg, decoder, content, style, alpha=1.0,
                   interpolation_weights=None):
    assert (0.0 <= alpha <= 1.0)
    # å°†åŸå›¾ content å’Œé£æ ¼å‚è€ƒå›¾ style ä¼ å…¥ç½‘ç»œ
    content_f = vgg(content)
    style_f = vgg(style)
    if interpolation_weights:
        _, C, H, W = content_f.size()
        feat = torch.FloatTensor(1, C, H, W).zero_().to(device)
        base_feat = adaptive_instance_normalization(content_f, style_f)
        for i, w in enumerate(interpolation_weights):
            feat = feat + w * base_feat[i:i + 1]
        content_f = content_f[0:1]

    else:
        feat = adaptive_instance_normalization(content_f, style_f)
    # èµ‹äºˆAdaINçš„è¾“å‡ºæƒé‡ Î±, å¹¶èµ‹äºˆ content å›¾åƒé€šè¿‡VGG Encoderåçš„è¾“å‡ºæƒé‡ 1-Î±
    # å·²å®ç°
    feat = feat * alpha + content_f * (1 - alpha)
    return decoder(feat)
```

æ‰§è¡ŒæŒ‡ä»¤ï¼š

ä½¿ç”¨ la_muse.jpg ä½œä¸ºé£æ ¼ç”»

```bash
python test.py --content input/content/bupt1.jpg --style input/style/la_muse.jpg --decoder experiments/decoder_iter_10000.pth.tar --alpha 0.3
python test.py --content input/content/bupt1.jpg --style input/style/la_muse.jpg --decoder experiments/decoder_iter_10000.pth.tar --alpha 0.6
python test.py --content input/content/bupt1.jpg --style input/style/la_muse.jpg --decoder experiments/decoder_iter_10000.pth.tar --alpha 0.9
```

### é£æ ¼å›¾

![23](./la_muse.jpg)

---

### è¾“å‡º

**æƒé‡=0.3**ï¼š

![bupt1_stylized_la_muse_alpha_0.300000.jpg](./bupt1_stylized_la_muse_alpha_0.300000.jpg)

**æƒé‡=0.6**ï¼š

![bupt1_stylized_la_muse_alpha_0.600000.jpg](./bupt1_stylized_la_muse_alpha_0.600000.jpg)

**æƒé‡=0.9**ï¼š

![bupt1_stylized_la_muse_alpha_0.900000.jpg](./bupt1_stylized_la_muse_alpha_0.900000.jpg)

> ï¼ˆè„‘å­é‡Œåªæœ‰å¯¹åˆ†æ•°çš„æ¸´æœ›ï¼Œå®Œå…¨æ²¡æœ‰å¯¹ç¾çš„è¿½æ±‚ï¼‰
